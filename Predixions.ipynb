{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064a513c-2e0c-4754-ae7f-5a74d49140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Python Notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Python Notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171c2b83-6c92-47a9-93dd-cb72ed24e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[33mWarning:\u001b[0m apache-spark 3.5.0 is already installed and up-to-date.\n",
      "To reinstall 3.5.0, run:\n",
      "  brew reinstall apache-spark\n"
     ]
    }
   ],
   "source": [
    "!brew install apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13003dd-ac5f-4337-aa16-634a33552ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed installing apache-spark\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed installing apache-spark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd91fb72-3dc8-47da-8a11-1cbb99d37387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m openjdk@11 11.0.20.1 is already installed and up-to-date.\n",
      "To reinstall 11.0.20.1, run:\n",
      "  brew reinstall openjdk@11\n"
     ]
    }
   ],
   "source": [
    "!brew install openjdk@11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6e1f8-eb81-4278-aaa7-6a0ee605a01b",
   "metadata": {},
   "source": [
    "### The above Java installation doesn't work immediately. If you do a \"re-install\" it tells which commands need to be run to fix the path variable etc.\n",
    "\n",
    "   ### (echo; echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"') >> /Users/ganapathychidambaram/.zprofile\n",
    "\n",
    "   \n",
    "   ### eval \"$(/opt/homebrew/bin/brew shellenv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0425c723-0643-4240-99fd-2b69e3de667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a38c1c6-21f0-4160-a73b-b86c276fa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export JAVA_HOME=/usr\n",
    "!export PATH=$JAVA_HOME/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18229829-990e-4c42-98ca-334af4589231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk 11.0.20.1 2023-08-24\n",
      "OpenJDK Runtime Environment Homebrew (build 11.0.20.1+0)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 11.0.20.1+0, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd784401-e13d-4d25-b350-48345abe1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export SPARK_HOME=/opt/homebrew/Cellar/apache-spark/3.3.0/libexec\n",
    "!export PATH=/opt/homebrew/Cellar/apache-spark/3.3.0/bin:$PATH\n",
    "\n",
    "# looks the case of the JAVA_HOME variable made all the difference    \n",
    "\n",
    "!export PYSPARK_SUBMIT_ARGS=\"--master local[3] pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dde423b-4dad-4a69-9c95-416684911096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/homebrew/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/homebrew/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: findspark in /opt/homebrew/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark\n",
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c088f31a-be45-4491-91be-032931a9221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36414768-d885-4265-b091-44dd1e7fb525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/26 20:53:57 WARN Utils: Your hostname, Ganapathys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.7 instead (on interface en0)\n",
      "23/09/26 20:53:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/26 20:53:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02160d43-3a56-451d-8430-dae67fd3051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"/Users/ganapathychidambaram/Desktop/predixions/apps.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda1c07e-60ba-4b73-91fb-42eac9e6dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+--------------------+-------+\n",
      "|UserID|WindowID|Split|     ApplicationDate|  JobID|\n",
      "+------+--------+-----+--------------------+-------+\n",
      "|    47|       1|Train|2012-04-04 15:56:...| 169528|\n",
      "|    47|       1|Train|2012-04-06 01:03:...| 284009|\n",
      "|    47|       1|Train|2012-04-05 02:40:...|   2121|\n",
      "|    47|       1|Train|2012-04-05 02:37:...| 848187|\n",
      "|    47|       1|Train|2012-04-05 22:44:...| 733748|\n",
      "|    47|       1|Train|2012-04-05 02:34:...| 576958|\n",
      "|    47|       1|Train|2012-04-05 22:55:...| 262470|\n",
      "|    47|       1|Train|2012-04-05 02:38:...| 602298|\n",
      "|    72|       1|Train|2012-04-02 22:36:...| 834662|\n",
      "|    72|       1|Train|2012-04-07 15:19:...|1020903|\n",
      "|    72|       1|Train|2012-04-07 17:38:...| 180313|\n",
      "|    72|       1|Train|2012-04-30 20:05:...| 480634|\n",
      "|    72|       1|Train|2012-04-20 02:51:...| 564184|\n",
      "|    80|       1|Train|2012-04-04 10:53:...| 908909|\n",
      "|   123|       1|Train|2012-04-02 20:57:...|1080147|\n",
      "|   123|       1|Train|2012-04-02 21:03:...|1080148|\n",
      "|   131|       1|Train|2012-04-02 14:06:...| 688863|\n",
      "|   131|       1|Train|2012-04-05 15:08:...|1092900|\n",
      "|   131|       1|Train|2012-04-05 17:09:...|  50183|\n",
      "|   162|       1|Train|2012-04-06 14:25:...|  69667|\n",
      "+------+--------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "applications_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ebe697-a1de-4dc3-b9b9-cb756d09b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/26 20:54:01 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 2:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "|summary|            UserID|          WindowID|  Split|     ApplicationDate|             JobID|\n",
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "|  count|           1603111|           1603111|1603111|             1603111|           1603111|\n",
      "|   mean| 762702.2528109407|3.6435674136101617|   null|                null| 565261.5271032386|\n",
      "| stddev|422564.90726027224|2.0290820972908996|   null|                null|323913.61690280534|\n",
      "|    min|           1000000|                 1|   Test|2012-04-01 00:00:...|                 1|\n",
      "|    max|            999982|                 7|  Train|2012-06-26 23:59:...|            999999|\n",
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "applications_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2078e2-c53b-4605-ae60-93c44108b464",
   "metadata": {},
   "source": [
    "pre-processing = Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b9a6a5-38cb-4c46-8136-158ea002ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_df = applications_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5b4a8bc-d386-403b-b91e-3a234f4e16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "|summary|            UserID|          WindowID|  Split|     ApplicationDate|             JobID|\n",
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "|  count|           1603111|           1603111|1603111|             1603111|           1603111|\n",
      "|   mean| 762702.2528109407|3.6435674136101617|   null|                null| 565261.5271032386|\n",
      "| stddev|422564.90726027224|2.0290820972908996|   null|                null|323913.61690280534|\n",
      "|    min|           1000000|                 1|   Test|2012-04-01 00:00:...|                 1|\n",
      "|    max|            999982|                 7|  Train|2012-06-26 23:59:...|            999999|\n",
      "+-------+------------------+------------------+-------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "applications_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f3a08e-c860-431a-a9e4-59136cf03a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"/Users/ganapathychidambaram/Desktop/predixions/users.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e95e9cc-c443-42cc-b07e-6018d312d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+\n",
      "|UserID|WindowID|Split|        City|State|Country|ZipCode| DegreeType|               Major|     GraduationDate|WorkHistoryCount|TotalYearsExperience|CurrentlyEmployed|ManagedOthers|ManagedHowMany|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+\n",
      "|    47|       1|Train|   Paramount|   CA|     US|  90723|High School|                null|1999-06-01 00:00:00|               3|                  10|              Yes|           No|             0|\n",
      "|    72|       1|Train|     La Mesa|   CA|     US|  91941|   Master's|        Anthropology|2011-01-01 00:00:00|              10|                   8|              Yes|           No|             0|\n",
      "|    80|       1|Train|Williamstown|   NJ|     US|  08094|High School|      Not Applicable|1985-06-01 00:00:00|               5|                  11|              Yes|          Yes|             5|\n",
      "|    98|       1|Train|     Astoria|   NY|     US|  11105|   Master's|          Journalism|2007-05-01 00:00:00|               3|                   3|              Yes|           No|             0|\n",
      "|   123|       1|Train| Baton Rouge|   LA|     US|  70808| Bachelor's|Agricultural Busi...|2011-05-01 00:00:00|               1|                   9|              Yes|           No|             0|\n",
      "|   131|       1|Train|     Houston|   TX|     US|  77077| Bachelor's|             Finance|1998-05-01 00:00:00|               3|                  14|             null|           No|             0|\n",
      "|   162|       1|Train|  Long Beach|   CA|     US|  90807|   Master's|      I/O Psychology|2012-05-01 00:00:00|              10|                  25|               No|           No|             0|\n",
      "|   178|       1|Train|  Greenville|   SC|     US|  29609|High School|      Not Applicable|               null|               6|                  35|               No|          Yes|             4|\n",
      "|   203|       1|Train|  Colchester|   VT|     US|  05446|   Master's|          Burlington|               null|               4|                   3|              Yes|           No|             0|\n",
      "|   344|       1|Train|Newport News|   VA|     US|  23601|High School|      Not Applicable|2007-01-01 00:00:00|               3|                   7|              Yes|           No|             0|\n",
      "|   395|       1|Train|    Wildwood|   MO|     US|  63038| Bachelor's|           Marketing|               null|              10|                  24|              Yes|           No|             0|\n",
      "|   411|       1|Train|        Lutz|   FL|     US|  33559|       None|                null|               null|               3|                  11|              Yes|          Yes|             1|\n",
      "|   415|       1|Train|      Leland|   NC|     US|  28451|Associate's|Office Systems Te...|2008-05-01 00:00:00|               5|                   7|             null|           No|             0|\n",
      "|   437|       1|Train|  Brookville|   OH|     US|  45309|Associate's|             Nursing|2010-05-01 00:00:00|               4|                  15|              Yes|           No|             0|\n",
      "|   483|       1|Train|        York|   PA|     US|  17406| Bachelor's|          Accounting|1989-01-01 00:00:00|               6|                  22|             null|           No|             0|\n",
      "|   496|       1|Train|      Easley|   SC|     US|  29640|High School|      Not Applicable|1987-01-01 00:00:00|              10|                  21|               No|           No|             0|\n",
      "|   501|       1|Train|  Cape Coral|   FL|     US|  33990| Bachelor's|                null|               null|               4|                  37|               No|           No|             0|\n",
      "|   524|       1|Train|    Florence|   SC|     US|  29501| Bachelor's|Restaurant and To...|               null|               5|                  20|              Yes|           No|             0|\n",
      "|   534|       1|Train|   Nashville|   TN|     US|  37214|High School|      Not Applicable|2009-01-01 00:00:00|               3|                   4|               No|           No|             0|\n",
      "|   547|       1|Train|     Milford|   CT|     US|  06460|High School|      Not Applicable|1989-01-01 00:00:00|               7|                  23|             null|           No|             0|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a549cff6-9a46-486f-97c9-bb2ca281e204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| DegreeType|\n",
      "+-----------+\n",
      "|High School|\n",
      "|       None|\n",
      "| Vocational|\n",
      "|        PhD|\n",
      "|Associate's|\n",
      "| Bachelor's|\n",
      "|   Master's|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_values = users_df.select('DegreeType').distinct()\n",
    "unique_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ffbb354-cd9c-41e3-9b69-50288c8bdb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47072\n"
     ]
    }
   ],
   "source": [
    "unique_values = users_df.select('Major').distinct()\n",
    "print(unique_values.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb3e554b-674a-4999-9ffb-f72557c3a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58760"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "users_df.filter(col('Major') == \"Not Applicable\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "456f43cf-62f0-40d1-8e11-f26364e7031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.filter(col('Major') == \"None\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b647b06-175e-429c-9095-9dfa2b224f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96897"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.filter(col('Major').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da707652-6988-4dcc-ae13-54f4d4c92b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.filter(col('Major') == \"null\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ba9b1-b725-41c9-8c0c-a6885248da14",
   "metadata": {},
   "source": [
    "Pre-processing - convert None to Not Applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26962a1c-e2d5-4b7d-9803-fd5424cef182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.filter(col('CurrentlyEmployed').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c554fea-a393-487a-9379-1b65d7f2e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with 'No' in a specific column (e.g., 'ColumnName')\n",
    "\n",
    "users_df = users_df.na.fill('No', ['CurrentlyEmployed', 'ManagedOthers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2a6e006-c17c-4106-90b9-d3a8476c2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|CurrentlyEmployed|\n",
      "+-----------------+\n",
      "|               No|\n",
      "|              Yes|\n",
      "+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|ManagedOthers|\n",
      "+-------------+\n",
      "|           No|\n",
      "|          Yes|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_values = users_df.select('CurrentlyEmployed').distinct()\n",
    "unique_values.show()\n",
    "\n",
    "unique_values = users_df.select('ManagedOthers').distinct()\n",
    "unique_values.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6474505e-612e-41d7-96ff-2d28a6d786e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.withColumn('Major', when(col('Major') == 'None', 'Not Applicable').otherwise(col('Major')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3ea83be-e0ee-4e39-aeb9-af77b2a40504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389708"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93985d9a-fc84-4b76-a449-ff6ea51a9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d60ca3ff-996b-4715-a201-9a1cc3888d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+\n",
      "|UserID|WindowID|Split|        City|State|Country|ZipCode| DegreeType|               Major|     GraduationDate|WorkHistoryCount|TotalYearsExperience|CurrentlyEmployed|ManagedOthers|ManagedHowMany|DegreeType_encoded|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+\n",
      "|    47|       1|Train|   Paramount|   CA|     US|  90723|High School|                null|1999-06-01 00:00:00|               3|                  10|              Yes|           No|             0|               2.0|\n",
      "|    72|       1|Train|     La Mesa|   CA|     US|  91941|   Master's|        Anthropology|2011-01-01 00:00:00|              10|                   8|              Yes|           No|             0|               4.0|\n",
      "|    80|       1|Train|Williamstown|   NJ|     US|  08094|High School|      Not Applicable|1985-06-01 00:00:00|               5|                  11|              Yes|          Yes|             5|               2.0|\n",
      "|    98|       1|Train|     Astoria|   NY|     US|  11105|   Master's|          Journalism|2007-05-01 00:00:00|               3|                   3|              Yes|           No|             0|               4.0|\n",
      "|   123|       1|Train| Baton Rouge|   LA|     US|  70808| Bachelor's|Agricultural Busi...|2011-05-01 00:00:00|               1|                   9|              Yes|           No|             0|               0.0|\n",
      "|   131|       1|Train|     Houston|   TX|     US|  77077| Bachelor's|             Finance|1998-05-01 00:00:00|               3|                  14|               No|           No|             0|               0.0|\n",
      "|   162|       1|Train|  Long Beach|   CA|     US|  90807|   Master's|      I/O Psychology|2012-05-01 00:00:00|              10|                  25|               No|           No|             0|               4.0|\n",
      "|   178|       1|Train|  Greenville|   SC|     US|  29609|High School|      Not Applicable|               null|               6|                  35|               No|          Yes|             4|               2.0|\n",
      "|   203|       1|Train|  Colchester|   VT|     US|  05446|   Master's|          Burlington|               null|               4|                   3|              Yes|           No|             0|               4.0|\n",
      "|   344|       1|Train|Newport News|   VA|     US|  23601|High School|      Not Applicable|2007-01-01 00:00:00|               3|                   7|              Yes|           No|             0|               2.0|\n",
      "|   395|       1|Train|    Wildwood|   MO|     US|  63038| Bachelor's|           Marketing|               null|              10|                  24|              Yes|           No|             0|               0.0|\n",
      "|   411|       1|Train|        Lutz|   FL|     US|  33559|       None|                null|               null|               3|                  11|              Yes|          Yes|             1|               1.0|\n",
      "|   415|       1|Train|      Leland|   NC|     US|  28451|Associate's|Office Systems Te...|2008-05-01 00:00:00|               5|                   7|               No|           No|             0|               3.0|\n",
      "|   437|       1|Train|  Brookville|   OH|     US|  45309|Associate's|             Nursing|2010-05-01 00:00:00|               4|                  15|              Yes|           No|             0|               3.0|\n",
      "|   483|       1|Train|        York|   PA|     US|  17406| Bachelor's|          Accounting|1989-01-01 00:00:00|               6|                  22|               No|           No|             0|               0.0|\n",
      "|   496|       1|Train|      Easley|   SC|     US|  29640|High School|      Not Applicable|1987-01-01 00:00:00|              10|                  21|               No|           No|             0|               2.0|\n",
      "|   501|       1|Train|  Cape Coral|   FL|     US|  33990| Bachelor's|                null|               null|               4|                  37|               No|           No|             0|               0.0|\n",
      "|   524|       1|Train|    Florence|   SC|     US|  29501| Bachelor's|Restaurant and To...|               null|               5|                  20|              Yes|           No|             0|               0.0|\n",
      "|   534|       1|Train|   Nashville|   TN|     US|  37214|High School|      Not Applicable|2009-01-01 00:00:00|               3|                   4|               No|           No|             0|               2.0|\n",
      "|   547|       1|Train|     Milford|   CT|     US|  06460|High School|      Not Applicable|1989-01-01 00:00:00|               7|                  23|               No|           No|             0|               2.0|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "string_indexer = StringIndexer(inputCol='DegreeType', outputCol='DegreeType_encoded')\n",
    "users_df_encoded = string_indexer.fit(users_df).transform(users_df)\n",
    "\n",
    "users_df_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fb28231-d058-436c-bfba-f8b3f278a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "|UserID|WindowID|Split|        City|State|Country|ZipCode| DegreeType|               Major|     GraduationDate|WorkHistoryCount|TotalYearsExperience|CurrentlyEmployed|ManagedOthers|ManagedHowMany|DegreeType_encoded|City_encoded|State_encoded|Country_encoded|CurrentlyEmployed_encoded|ManagedOthers_encoded|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "|    47|       1|Train|   Paramount|   CA|     US|  90723|High School|                null|1999-06-01 00:00:00|               3|                  10|              Yes|           No|             0|               2.0|       924.0|          2.0|            0.0|                      0.0|                  0.0|\n",
      "|    72|       1|Train|     La Mesa|   CA|     US|  91941|   Master's|        Anthropology|2011-01-01 00:00:00|              10|                   8|              Yes|           No|             0|               4.0|      1052.0|          2.0|            0.0|                      0.0|                  0.0|\n",
      "|    80|       1|Train|Williamstown|   NJ|     US|  08094|High School|      Not Applicable|1985-06-01 00:00:00|               5|                  11|              Yes|          Yes|             5|               2.0|       624.0|          7.0|            0.0|                      0.0|                  1.0|\n",
      "|    98|       1|Train|     Astoria|   NY|     US|  11105|   Master's|          Journalism|2007-05-01 00:00:00|               3|                   3|              Yes|           No|             0|               4.0|       407.0|          4.0|            0.0|                      0.0|                  0.0|\n",
      "|   123|       1|Train| Baton Rouge|   LA|     US|  70808| Bachelor's|Agricultural Busi...|2011-05-01 00:00:00|               1|                   9|              Yes|           No|             0|               0.0|        91.0|         24.0|            0.0|                      0.0|                  0.0|\n",
      "|   131|       1|Train|     Houston|   TX|     US|  77077| Bachelor's|             Finance|1998-05-01 00:00:00|               3|                  14|               No|           No|             0|               0.0|         1.0|          1.0|            0.0|                      1.0|                  0.0|\n",
      "|   162|       1|Train|  Long Beach|   CA|     US|  90807|   Master's|      I/O Psychology|2012-05-01 00:00:00|              10|                  25|               No|           No|             0|               4.0|        50.0|          2.0|            0.0|                      1.0|                  0.0|\n",
      "|   178|       1|Train|  Greenville|   SC|     US|  29609|High School|      Not Applicable|               null|               6|                  35|               No|          Yes|             4|               2.0|        51.0|         16.0|            0.0|                      1.0|                  1.0|\n",
      "|   203|       1|Train|  Colchester|   VT|     US|  05446|   Master's|          Burlington|               null|               4|                   3|              Yes|           No|             0|               4.0|      1333.0|         45.0|            0.0|                      0.0|                  0.0|\n",
      "|   344|       1|Train|Newport News|   VA|     US|  23601|High School|      Not Applicable|2007-01-01 00:00:00|               3|                   7|              Yes|           No|             0|               2.0|        95.0|         14.0|            0.0|                      0.0|                  0.0|\n",
      "|   395|       1|Train|    Wildwood|   MO|     US|  63038| Bachelor's|           Marketing|               null|              10|                  24|              Yes|           No|             0|               0.0|      1915.0|         17.0|            0.0|                      0.0|                  0.0|\n",
      "|   411|       1|Train|        Lutz|   FL|     US|  33559|       None|                null|               null|               3|                  11|              Yes|          Yes|             1|               1.0|       649.0|          0.0|            0.0|                      0.0|                  1.0|\n",
      "|   415|       1|Train|      Leland|   NC|     US|  28451|Associate's|Office Systems Te...|2008-05-01 00:00:00|               5|                   7|               No|           No|             0|               3.0|      2483.0|          9.0|            0.0|                      1.0|                  0.0|\n",
      "|   437|       1|Train|  Brookville|   OH|     US|  45309|Associate's|             Nursing|2010-05-01 00:00:00|               4|                  15|              Yes|           No|             0|               3.0|      1807.0|          8.0|            0.0|                      0.0|                  0.0|\n",
      "|   483|       1|Train|        York|   PA|     US|  17406| Bachelor's|          Accounting|1989-01-01 00:00:00|               6|                  22|               No|           No|             0|               0.0|       189.0|          5.0|            0.0|                      1.0|                  0.0|\n",
      "|   496|       1|Train|      Easley|   SC|     US|  29640|High School|      Not Applicable|1987-01-01 00:00:00|              10|                  21|               No|           No|             0|               2.0|       691.0|         16.0|            0.0|                      1.0|                  0.0|\n",
      "|   501|       1|Train|  Cape Coral|   FL|     US|  33990| Bachelor's|                null|               null|               4|                  37|               No|           No|             0|               0.0|       142.0|          0.0|            0.0|                      1.0|                  0.0|\n",
      "|   524|       1|Train|    Florence|   SC|     US|  29501| Bachelor's|Restaurant and To...|               null|               5|                  20|              Yes|           No|             0|               0.0|       145.0|         16.0|            0.0|                      0.0|                  0.0|\n",
      "|   534|       1|Train|   Nashville|   TN|     US|  37214|High School|      Not Applicable|2009-01-01 00:00:00|               3|                   4|               No|           No|             0|               2.0|        33.0|         15.0|            0.0|                      1.0|                  0.0|\n",
      "|   547|       1|Train|     Milford|   CT|     US|  06460|High School|      Not Applicable|1989-01-01 00:00:00|               7|                  23|               No|           No|             0|               2.0|       223.0|         19.0|            0.0|                      1.0|                  0.0|\n",
      "+------+--------+-----+------------+-----+-------+-------+-----------+--------------------+-------------------+----------------+--------------------+-----------------+-------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Numerically encode these columns ['City', 'State', 'Country', 'CurrentlyEmployed', 'ManagedOthers']\n",
    "categorical_columns = ['City', 'State', 'Country', 'CurrentlyEmployed', 'ManagedOthers']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    encoded_column = col + \"_encoded\"\n",
    "    string_indexer = StringIndexer(inputCol=col, outputCol=encoded_column)\n",
    "    users_df_encoded = string_indexer.fit(users_df_encoded).transform(users_df_encoded)\n",
    "\n",
    "# Show the resulting DataFrame with the encoded column\n",
    "users_df_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a352282d-48e2-4d22-bfd1-7788290d92b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+-------+--------------------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "|UserID|WindowID|Split|ZipCode|               Major|     GraduationDate|WorkHistoryCount|TotalYearsExperience|ManagedHowMany|DegreeType_encoded|City_encoded|State_encoded|Country_encoded|CurrentlyEmployed_encoded|ManagedOthers_encoded|\n",
      "+------+--------+-----+-------+--------------------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "|    47|       1|Train|  90723|                null|1999-06-01 00:00:00|               3|                  10|             0|               2.0|       924.0|          2.0|            0.0|                      0.0|                  0.0|\n",
      "|    72|       1|Train|  91941|        Anthropology|2011-01-01 00:00:00|              10|                   8|             0|               4.0|      1052.0|          2.0|            0.0|                      0.0|                  0.0|\n",
      "|    80|       1|Train|  08094|      Not Applicable|1985-06-01 00:00:00|               5|                  11|             5|               2.0|       624.0|          7.0|            0.0|                      0.0|                  1.0|\n",
      "|    98|       1|Train|  11105|          Journalism|2007-05-01 00:00:00|               3|                   3|             0|               4.0|       407.0|          4.0|            0.0|                      0.0|                  0.0|\n",
      "|   123|       1|Train|  70808|Agricultural Busi...|2011-05-01 00:00:00|               1|                   9|             0|               0.0|        91.0|         24.0|            0.0|                      0.0|                  0.0|\n",
      "|   131|       1|Train|  77077|             Finance|1998-05-01 00:00:00|               3|                  14|             0|               0.0|         1.0|          1.0|            0.0|                      1.0|                  0.0|\n",
      "|   162|       1|Train|  90807|      I/O Psychology|2012-05-01 00:00:00|              10|                  25|             0|               4.0|        50.0|          2.0|            0.0|                      1.0|                  0.0|\n",
      "|   178|       1|Train|  29609|      Not Applicable|               null|               6|                  35|             4|               2.0|        51.0|         16.0|            0.0|                      1.0|                  1.0|\n",
      "|   203|       1|Train|  05446|          Burlington|               null|               4|                   3|             0|               4.0|      1333.0|         45.0|            0.0|                      0.0|                  0.0|\n",
      "|   344|       1|Train|  23601|      Not Applicable|2007-01-01 00:00:00|               3|                   7|             0|               2.0|        95.0|         14.0|            0.0|                      0.0|                  0.0|\n",
      "|   395|       1|Train|  63038|           Marketing|               null|              10|                  24|             0|               0.0|      1915.0|         17.0|            0.0|                      0.0|                  0.0|\n",
      "|   411|       1|Train|  33559|                null|               null|               3|                  11|             1|               1.0|       649.0|          0.0|            0.0|                      0.0|                  1.0|\n",
      "|   415|       1|Train|  28451|Office Systems Te...|2008-05-01 00:00:00|               5|                   7|             0|               3.0|      2483.0|          9.0|            0.0|                      1.0|                  0.0|\n",
      "|   437|       1|Train|  45309|             Nursing|2010-05-01 00:00:00|               4|                  15|             0|               3.0|      1807.0|          8.0|            0.0|                      0.0|                  0.0|\n",
      "|   483|       1|Train|  17406|          Accounting|1989-01-01 00:00:00|               6|                  22|             0|               0.0|       189.0|          5.0|            0.0|                      1.0|                  0.0|\n",
      "|   496|       1|Train|  29640|      Not Applicable|1987-01-01 00:00:00|              10|                  21|             0|               2.0|       691.0|         16.0|            0.0|                      1.0|                  0.0|\n",
      "|   501|       1|Train|  33990|                null|               null|               4|                  37|             0|               0.0|       142.0|          0.0|            0.0|                      1.0|                  0.0|\n",
      "|   524|       1|Train|  29501|Restaurant and To...|               null|               5|                  20|             0|               0.0|       145.0|         16.0|            0.0|                      0.0|                  0.0|\n",
      "|   534|       1|Train|  37214|      Not Applicable|2009-01-01 00:00:00|               3|                   4|             0|               2.0|        33.0|         15.0|            0.0|                      1.0|                  0.0|\n",
      "|   547|       1|Train|  06460|      Not Applicable|1989-01-01 00:00:00|               7|                  23|             0|               2.0|       223.0|         19.0|            0.0|                      1.0|                  0.0|\n",
      "+------+--------+-----+-------+--------------------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['City', 'State', 'Country', 'CurrentlyEmployed', 'ManagedOthers', 'DegreeType']\n",
    "users_df_encoded = users_df_encoded.drop(*columns_to_drop)\n",
    "users_df_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ac5a67e-2160-4324-a12f-c4c5d5d55ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+-------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+---------------+\n",
      "|UserID|WindowID|Split|ZipCode|     GraduationDate|WorkHistoryCount|TotalYearsExperience|ManagedHowMany|DegreeType_encoded|City_encoded|State_encoded|Country_encoded|CurrentlyEmployed_encoded|ManagedOthers_encoded|major_frequency|\n",
      "+------+--------+-----+-------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+---------------+\n",
      "|    47|       1|Train|  90723|1999-06-01 00:00:00|               3|                  10|             0|               2.0|       924.0|          2.0|            0.0|                      0.0|                  0.0|              0|\n",
      "|    72|       1|Train|  91941|2011-01-01 00:00:00|              10|                   8|             0|               4.0|      1052.0|          2.0|            0.0|                      0.0|                  0.0|            191|\n",
      "|    80|       1|Train|  08094|1985-06-01 00:00:00|               5|                  11|             5|               2.0|       624.0|          7.0|            0.0|                      0.0|                  1.0|          58823|\n",
      "|    98|       1|Train|  11105|2007-05-01 00:00:00|               3|                   3|             0|               4.0|       407.0|          4.0|            0.0|                      0.0|                  0.0|            529|\n",
      "|   123|       1|Train|  70808|2011-05-01 00:00:00|               1|                   9|             0|               0.0|        91.0|         24.0|            0.0|                      0.0|                  0.0|             12|\n",
      "|   131|       1|Train|  77077|1998-05-01 00:00:00|               3|                  14|             0|               0.0|         1.0|          1.0|            0.0|                      1.0|                  0.0|           2818|\n",
      "|   162|       1|Train|  90807|2012-05-01 00:00:00|              10|                  25|             0|               4.0|        50.0|          2.0|            0.0|                      1.0|                  0.0|              5|\n",
      "|   178|       1|Train|  29609|               null|               6|                  35|             4|               2.0|        51.0|         16.0|            0.0|                      1.0|                  1.0|          58823|\n",
      "|   203|       1|Train|  05446|               null|               4|                   3|             0|               4.0|      1333.0|         45.0|            0.0|                      0.0|                  0.0|              1|\n",
      "|   344|       1|Train|  23601|2007-01-01 00:00:00|               3|                   7|             0|               2.0|        95.0|         14.0|            0.0|                      0.0|                  0.0|          58823|\n",
      "|   395|       1|Train|  63038|               null|              10|                  24|             0|               0.0|      1915.0|         17.0|            0.0|                      0.0|                  0.0|           2911|\n",
      "|   411|       1|Train|  33559|               null|               3|                  11|             1|               1.0|       649.0|          0.0|            0.0|                      0.0|                  1.0|              0|\n",
      "|   415|       1|Train|  28451|2008-05-01 00:00:00|               5|                   7|             0|               3.0|      2483.0|          9.0|            0.0|                      1.0|                  0.0|             33|\n",
      "|   437|       1|Train|  45309|2010-05-01 00:00:00|               4|                  15|             0|               3.0|      1807.0|          8.0|            0.0|                      0.0|                  0.0|           2886|\n",
      "|   483|       1|Train|  17406|1989-01-01 00:00:00|               6|                  22|             0|               0.0|       189.0|          5.0|            0.0|                      1.0|                  0.0|           7576|\n",
      "|   496|       1|Train|  29640|1987-01-01 00:00:00|              10|                  21|             0|               2.0|       691.0|         16.0|            0.0|                      1.0|                  0.0|          58823|\n",
      "|   501|       1|Train|  33990|               null|               4|                  37|             0|               0.0|       142.0|          0.0|            0.0|                      1.0|                  0.0|              0|\n",
      "|   524|       1|Train|  29501|               null|               5|                  20|             0|               0.0|       145.0|         16.0|            0.0|                      0.0|                  0.0|              4|\n",
      "|   534|       1|Train|  37214|2009-01-01 00:00:00|               3|                   4|             0|               2.0|        33.0|         15.0|            0.0|                      1.0|                  0.0|          58823|\n",
      "|   547|       1|Train|  06460|1989-01-01 00:00:00|               7|                  23|             0|               2.0|       223.0|         19.0|            0.0|                      1.0|                  0.0|          58823|\n",
      "+------+--------+-----+-------+-------------------+----------------+--------------------+--------------+------------------+------------+-------------+---------------+-------------------------+---------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, lit\n",
    "\n",
    "# Calculate the frequency of each unique value in the 'Major' column\n",
    "major_frequencies = users_df_encoded.groupBy('Major').agg(count(lit(1)).alias('major_frequency'))\n",
    "\n",
    "# Join the frequency information back to the original DataFrame\n",
    "users_df_encoded = users_df_encoded.join(major_frequencies, on='Major', how='left')\n",
    "\n",
    "# Replace null values in the 'Frequency' column with 0\n",
    "users_df_encoded = users_df_encoded.na.fill(0, ['major_frequency'])\n",
    "\n",
    "users_df_encoded = users_df_encoded.drop('Major')\n",
    "users_df_encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42eff8a9-4a04-4821-ae61-57fd4e2bbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"/Users/ganapathychidambaram/Desktop/predixions/user_history.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f502c090-6fff-479b-b84e-28a1f95ec128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+--------+--------------------+\n",
      "|UserID|WindowID|Split|Sequence|            JobTitle|\n",
      "+------+--------+-----+--------+--------------------+\n",
      "|    47|       1|Train|       1|National Space Co...|\n",
      "|    47|       1|Train|       2|   Detention Officer|\n",
      "|    47|       1|Train|       3|Passenger Screene...|\n",
      "|    72|       1|Train|       1|Lecturer, Departm...|\n",
      "|    72|       1|Train|       2|   Student Assistant|\n",
      "|    72|       1|Train|       3|   Elderly Caregiver|\n",
      "|    72|       1|Train|       4|                null|\n",
      "|    72|       1|Train|       5|Department Assist...|\n",
      "|    72|       1|Train|       6|Book Reviews Edit...|\n",
      "|    72|       1|Train|       7|  Graduate Assistant|\n",
      "|    72|       1|Train|       8|                null|\n",
      "|    72|       1|Train|       9|  Research Assistant|\n",
      "|    72|       1|Train|      10|Docent, C.E. Smit...|\n",
      "|    80|       1|Train|       1|Auto Publishing/E...|\n",
      "|    80|       1|Train|       2|Enhanced Baker Ce...|\n",
      "|    80|       1|Train|       3|Lead was  was als...|\n",
      "|    80|       1|Train|       4|Sales Associate, ...|\n",
      "|    80|       1|Train|       5|Enhanced Baker Ce...|\n",
      "|    98|       1|Train|       1|     Editor-in-Chief|\n",
      "|    98|       1|Train|       2|Deputy Sports & W...|\n",
      "+------+--------+-----+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_history_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0916182b-0a81-4e6c-857f-699799d7df8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657162"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = user_history_df.select('JobTitle').distinct()\n",
    "unique_values.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c78d9f36-a770-40c0-95f8-ca690ce32f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753901"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e078de-dde1-4c29-9a2c-bb7cc6723ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|            JobTitle|job_title_freq|\n",
      "+--------------------+--------------+\n",
      "|Commercial and re...|             1|\n",
      "|      Service Writer|           109|\n",
      "|Relief Production...|             1|\n",
      "|Lead Field Techni...|             1|\n",
      "|Pa. - Business Un...|             1|\n",
      "|Field - Service E...|             1|\n",
      "|Journeyman Electr...|           447|\n",
      "|          Enumerator|           240|\n",
      "|Health Service Sp...|             1|\n",
      "|CUSTODIAN OF MEDI...|             1|\n",
      "|   Procurement Buyer|             3|\n",
      "|         Bank Teller|          1081|\n",
      "|Customer Service ...|             1|\n",
      "|Sr. Staffing & St...|             1|\n",
      "|Minster Press Ope...|             1|\n",
      "|Country General M...|             1|\n",
      "|   Compliance Intern|             5|\n",
      "|Account Services ...|             8|\n",
      "|Paralegal Supervisor|             6|\n",
      "|Commercial Loan C...|             1|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_title_frequencies = user_history_df.groupBy('JobTitle').agg(count(lit(1)).alias('job_title_freq'))\n",
    "job_title_frequencies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f900570-b089-42c7-99dc-af27feca3549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+--------+--------------+\n",
      "| UserID|WindowID|Split|Sequence|job_title_freq|\n",
      "+-------+--------+-----+--------+--------------+\n",
      "| 393222|       4|Train|       3|             1|\n",
      "| 393090|       4|Train|       4|           249|\n",
      "| 393090|       4|Train|       5|           249|\n",
      "| 586219|       7|Train|       1|             1|\n",
      "|1034616|       1|Train|       1|            15|\n",
      "|1034634|       1|Train|       3|             1|\n",
      "| 393090|       4|Train|       6|             1|\n",
      "| 337715|       5|Train|       5|            15|\n",
      "|     80|       1|Train|       3|             1|\n",
      "| 586173|       7|Train|       7|           132|\n",
      "| 515554|       3|Train|       2|             1|\n",
      "| 709314|       2|Train|       2|             1|\n",
      "| 586173|       7|Train|       5|            41|\n",
      "|1034664|       1|Train|       3|         15645|\n",
      "| 395265|       6|Train|       5|         15645|\n",
      "| 586221|       7|Train|       2|         15645|\n",
      "| 337728|       5|Train|       3|             1|\n",
      "| 709176|       2|Train|       4|          7378|\n",
      "| 395293|       6|Train|       3|             3|\n",
      "| 515546|       3|Train|       3|             1|\n",
      "+-------+--------+-----+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Join the frequency information back to the original DataFrame\n",
    "user_history_df = user_history_df.join(job_title_frequencies, on='JobTitle', how='left')\n",
    "\n",
    "# Replace null values in the 'Frequency' column with 0\n",
    "user_history_df = user_history_df.na.fill(0, ['job_title_freq'])\n",
    "\n",
    "# Drop the original 'JobTitle' column\n",
    "user_history_df = user_history_df.drop('JobTitle')\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "user_history_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "371e3e4b-4c47-4b49-acb4-1bb23e43c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, first\n",
    "\n",
    "\n",
    "compressed_user_hist_df = user_history_df.groupBy('UserID').agg(\n",
    "    collect_list('Sequence').alias('Sequence'),\n",
    "    collect_list('job_title_freq').alias('job_title_freq'),\n",
    "    first('WindowID').alias('WindowID'),\n",
    "    first('Split').alias('Split')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0caef775-4d31-4d60-94c7-5dc2a3a297f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:================================>                         (5 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------+-----+\n",
      "| UserID|            Sequence|      job_title_freq|WindowID|Split|\n",
      "+-------+--------------------+--------------------+--------+-----+\n",
      "|1000015|[2, 5, 3, 7, 6, 1...|[913, 634, 1, 15,...|       1| Test|\n",
      "|1000070|        [4, 3, 2, 1]|[8577, 161, 41, 278]|       7|Train|\n",
      "|1000127|        [4, 1, 2, 3]|  [1513, 47, 47, 47]|       7|Train|\n",
      "|1000128|[1, 2, 6, 4, 3, 5...|[164, 11, 159, 1,...|       7|Train|\n",
      "|1000131|[4, 1, 6, 3, 5, 2...|[13, 238, 1, 274,...|       5|Train|\n",
      "| 100014|     [1, 3, 4, 5, 2]| [1813, 0, 0, 0, 36]|       4|Train|\n",
      "|1000205|                 [1]|                 [1]|       5|Train|\n",
      "|1000272|        [4, 1, 3, 2]|  [2779, 8577, 1, 1]|       3|Train|\n",
      "|1000284|     [5, 4, 2, 1, 3]|[97, 1, 181, 1622...|       7|Train|\n",
      "|1000316|[7, 1, 6, 2, 3, 5...|[218, 2, 2, 1, 1,...|       1|Train|\n",
      "|1000353|           [3, 1, 2]|         [272, 1, 1]|       4|Train|\n",
      "|1000401|                 [1]|                 [1]|       2|Train|\n",
      "|1000429|  [2, 6, 5, 4, 1, 3]|[1578, 1, 10, 151...|       1|Train|\n",
      "|1000482|[9, 5, 6, 4, 10, ...|[16368, 16, 30, 1...|       1|Train|\n",
      "|1000495|     [3, 1, 2, 5, 4]|[91, 4279, 4279, ...|       3|Train|\n",
      "|1000569|[2, 4, 6, 7, 3, 5...|[15645, 15645, 15...|       3|Train|\n",
      "|1000572|        [3, 4, 1, 2]|        [1, 0, 1, 1]|       1|Train|\n",
      "|1000619|     [1, 5, 3, 2, 4]|  [172, 1, 1, 56, 1]|       7|Train|\n",
      "| 100062|              [1, 2]|             [1, 41]|       6|Train|\n",
      "|1000725|     [3, 4, 5, 1, 2]|  [42, 42, 42, 1, 1]|       6|Train|\n",
      "+-------+--------------------+--------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "compressed_user_hist_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "283bd87d-1d15-4602-83f7-addca95d5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"/Users/ganapathychidambaram/Desktop/predixions/jobs.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcb71cd5-4fde-444a-9652-d994fa0e66ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "|JobID|WindowID|               Title|         Description|        Requirements|             City|State|Country| Zip5|           StartDate|            EndDate|\n",
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "|    1|       1|Security Engineer...|<p>Security Clear...|<p>SKILL SET</p>\\...|       Washington|   DC|     US|20531|2012-03-07 13:17:...|2012-04-06 23:59:59|\n",
      "|    4|       1|SAP Business Anal...|<strong>NO Corp. ...|<p><b>WHAT YOU NE...|        Charlotte|   NC|     US|28217|2012-03-21 02:03:...|2012-04-20 23:59:59|\n",
      "|    7|       1|P/T HUMAN RESOURC...|<b>    <b> P/T HU...|Please refer to t...|      Winter Park|   FL|     US|32792|2012-03-02 16:36:...|2012-04-01 23:59:59|\n",
      "|    8|       1|Route Delivery Dr...|CITY BEVERAGES Co...|Please refer to t...|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|\n",
      "|    9|       1|        Housekeeping|I make  sure ever...|Please refer to t...|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|\n",
      "|   10|       1|SALON/SPA COORDIN...|<b>    <b> SALON...|Please refer to t...|     Ormond Beach|   FL|     US|32174|2012-03-05 14:21:...|2012-04-04 23:59:59|\n",
      "|   11|       1|      SUPERINTENDENT|<b>    <b>SUPERIN...|Please refer to t...|          Orlando|   FL|     US|32801|2012-03-06 09:21:...|2012-04-05 23:59:59|\n",
      "|   12|       1|ELECTRONIC PRE-PR...|<b>    <b>ELECTRO...|Please refer to t...|          Orlando|   FL|     US|32808|2012-03-06 11:21:...|2012-04-05 23:59:59|\n",
      "|   13|       1|UTILITY LINE TRUC...|<b>     </b> \\r\\n...|Please refer to t...|          Orlando|   FL|     US|32801|2012-03-06 16:06:...|2012-04-05 23:59:59|\n",
      "|   14|       1|CONSTRUCTION PROJ...|<b>    <b>CONSTRU...|Please refer to t...|      Winter Park|   FL|     US|32789|2012-03-07 10:21:...|2012-04-06 23:59:59|\n",
      "|   15|       1|Administrative As...|This Administrati...|Please refer to t...|      Los Angeles|   CA|     US|90011|2012-03-09 01:12:...|2012-04-08 23:59:59|\n",
      "|   16|       1|  ACCOUNT EXECUTIVES|<b>    <b>ACCOUNT...|Please refer to t...|         Longwood|   FL|     US|32779|2012-03-08 05:09:...|2012-04-07 23:59:59|\n",
      "|   17|       1|COMMERCIAL ESTIMATOR|<b>    <b>TRI-CIT...|Please refer to t...|Altamonte Springs|   FL|     US|32714|2012-03-08 11:07:...|2012-04-07 23:59:59|\n",
      "|   18|       1|   Immediate Opening|Immediate Opening...|Please refer to t...|          Orlando|   FL|     US|32819|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   19|       1|        TESL Adjunct|TESL Adjunct - Th...|Please refer to t...|    Daytona Beach|   FL|     US|32114|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   20|       1|Salon Manager/Hai...|Salon Manager/Hai...|Please refer to t...|           Oviedo|   FL|     US|32765|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   21|       1|VOCATIONAL COUNSELOR|<b>    <b>VOCATIO...|Please refer to t...|          Orlando|   FL|     US|32804|2012-03-09 16:21:...|2012-04-08 23:59:59|\n",
      "|   22|       1|GALLERY SALES POS...|<b>    <b>       ...|Please refer to t...|          Orlando|   FL|     US|32819|2012-03-09 16:51:...|2012-04-08 23:59:59|\n",
      "|   23|       1| SURGICAL SCRUB TECH|<b>    <b> SURGIC...|Please refer to t...|Altamonte Springs|   FL|     US|32701|2012-03-09 17:06:...|2012-04-08 23:59:59|\n",
      "|   24|       1|   Real Estate Agent|Now accepting Sea...|Please refer to t...|       Windermere|   FL|     US|34786|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jobs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77267b09-8fe5-40f2-acc7-d576a84c8661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "|JobID|WindowID|               Title|         Description|        Requirements|             City|State|Country| Zip5|           StartDate|            EndDate|\n",
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "|    1|       1|Security Engineer...|<p>Security Clear...|<p>SKILL SET</p>\\...|       Washington|   DC|     US|20531|2012-03-07 13:17:...|2012-04-06 23:59:59|\n",
      "|    4|       1|SAP Business Anal...|<strong>NO Corp. ...|<p><b>WHAT YOU NE...|        Charlotte|   NC|     US|28217|2012-03-21 02:03:...|2012-04-20 23:59:59|\n",
      "|    7|       1|P/T HUMAN RESOURC...|<b>    <b> P/T HU...|Please refer to t...|      Winter Park|   FL|     US|32792|2012-03-02 16:36:...|2012-04-01 23:59:59|\n",
      "|    8|       1|Route Delivery Dr...|CITY BEVERAGES Co...|Please refer to t...|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|\n",
      "|    9|       1|        Housekeeping|I make  sure ever...|Please refer to t...|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|\n",
      "|   10|       1|SALON/SPA COORDIN...|<b>    <b> SALON...|Please refer to t...|     Ormond Beach|   FL|     US|32174|2012-03-05 14:21:...|2012-04-04 23:59:59|\n",
      "|   11|       1|      SUPERINTENDENT|<b>    <b>SUPERIN...|Please refer to t...|          Orlando|   FL|     US|32801|2012-03-06 09:21:...|2012-04-05 23:59:59|\n",
      "|   12|       1|ELECTRONIC PRE-PR...|<b>    <b>ELECTRO...|Please refer to t...|          Orlando|   FL|     US|32808|2012-03-06 11:21:...|2012-04-05 23:59:59|\n",
      "|   13|       1|UTILITY LINE TRUC...|<b>     </b> \\r\\n...|Please refer to t...|          Orlando|   FL|     US|32801|2012-03-06 16:06:...|2012-04-05 23:59:59|\n",
      "|   14|       1|CONSTRUCTION PROJ...|<b>    <b>CONSTRU...|Please refer to t...|      Winter Park|   FL|     US|32789|2012-03-07 10:21:...|2012-04-06 23:59:59|\n",
      "|   15|       1|Administrative As...|This Administrati...|Please refer to t...|      Los Angeles|   CA|     US|90011|2012-03-09 01:12:...|2012-04-08 23:59:59|\n",
      "|   16|       1|  ACCOUNT EXECUTIVES|<b>    <b>ACCOUNT...|Please refer to t...|         Longwood|   FL|     US|32779|2012-03-08 05:09:...|2012-04-07 23:59:59|\n",
      "|   17|       1|COMMERCIAL ESTIMATOR|<b>    <b>TRI-CIT...|Please refer to t...|Altamonte Springs|   FL|     US|32714|2012-03-08 11:07:...|2012-04-07 23:59:59|\n",
      "|   18|       1|   Immediate Opening|Immediate Opening...|Please refer to t...|          Orlando|   FL|     US|32819|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   19|       1|        TESL Adjunct|TESL Adjunct - Th...|Please refer to t...|    Daytona Beach|   FL|     US|32114|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   20|       1|Salon Manager/Hai...|Salon Manager/Hai...|Please refer to t...|           Oviedo|   FL|     US|32765|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "|   21|       1|VOCATIONAL COUNSELOR|<b>    <b>VOCATIO...|Please refer to t...|          Orlando|   FL|     US|32804|2012-03-09 16:21:...|2012-04-08 23:59:59|\n",
      "|   22|       1|GALLERY SALES POS...|<b>    <b>       ...|Please refer to t...|          Orlando|   FL|     US|32819|2012-03-09 16:51:...|2012-04-08 23:59:59|\n",
      "|   23|       1| SURGICAL SCRUB TECH|<b>    <b> SURGIC...|Please refer to t...|Altamonte Springs|   FL|     US|32701|2012-03-09 17:06:...|2012-04-08 23:59:59|\n",
      "|   24|       1|   Real Estate Agent|Now accepting Sea...|Please refer to t...|       Windermere|   FL|     US|34786|2012-03-10 01:13:...|2012-04-09 23:59:59|\n",
      "+-----+--------+--------------------+--------------------+--------------------+-----------------+-----+-------+-----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace null values in 'Title' column with an empty string\n",
    "jobs_df = jobs_df.withColumn(\"Title\", when(jobs_df[\"Title\"].isNull(), \"\").otherwise(jobs_df[\"Title\"]))\n",
    "\n",
    "# Replace null values in 'Description' and 'Requirements' columns\n",
    "jobs_df = jobs_df.fillna({\"Description\": \"<p>No description available</p>\", \"Requirements\": \"<p>No requirements available</p>\"})\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "jobs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "317cfc03-9b27-4508-a27c-1174bb0ad9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_1 in memory! (computed 18.9 MiB so far)\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_6 in memory! (computed 15.0 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_1 to disk instead.\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_6 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_0 in memory! (computed 14.5 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_0 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_4 in memory! (computed 19.3 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_4 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_2 in memory! (computed 19.2 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_2 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_5 in memory! (computed 19.6 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_5 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_3 in memory! (computed 18.3 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_3 to disk instead.\n",
      "23/09/26 20:55:41 WARN MemoryStore: Not enough space to cache rdd_279_7 in memory! (computed 5.6 MiB so far)\n",
      "23/09/26 20:55:41 WARN BlockManager: Persisting block rdd_279_7 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_12 in memory! (computed 1538.5 KiB so far)\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_13 in memory! (computed 1540.0 KiB so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_13 to disk instead.\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_12 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_279_11 in memory.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_11 in memory! (computed 384.0 B so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_11 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_10 in memory! (computed 1024.8 KiB so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_10 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_9 in memory! (computed 1047.8 KiB so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_9 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_15 in memory! (computed 1026.6 KiB so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_15 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_14 in memory! (computed 5.1 MiB so far)\n",
      "23/09/26 20:55:43 WARN BlockManager: Persisting block rdd_279_14 to disk instead.\n",
      "23/09/26 20:55:43 WARN MemoryStore: Not enough space to cache rdd_279_11 in memory! (computed 28.5 MiB so far)\n",
      "23/09/26 20:55:44 WARN MemoryStore: Not enough space to cache rdd_279_16 in memory! (computed 21.4 MiB so far)\n",
      "23/09/26 20:55:44 WARN BlockManager: Persisting block rdd_279_16 to disk instead.\n",
      "23/09/26 20:55:44 WARN MemoryStore: Not enough space to cache rdd_279_20 in memory! (computed 1540.2 KiB so far)\n",
      "23/09/26 20:55:44 WARN MemoryStore: Not enough space to cache rdd_279_21 in memory! (computed 1539.0 KiB so far)\n",
      "23/09/26 20:55:44 WARN BlockManager: Persisting block rdd_279_21 to disk instead.\n",
      "23/09/26 20:55:44 WARN MemoryStore: Not enough space to cache rdd_279_18 in memory! (computed 12.4 MiB so far)\n",
      "23/09/26 20:55:44 WARN BlockManager: Persisting block rdd_279_18 to disk instead.\n",
      "23/09/26 20:55:44 WARN BlockManager: Persisting block rdd_279_20 to disk instead.\n",
      "23/09/26 20:55:45 WARN MemoryStore: Not enough space to cache rdd_279_19 in memory! (computed 3.7 MiB so far)\n",
      "23/09/26 20:55:45 WARN BlockManager: Persisting block rdd_279_19 to disk instead.\n",
      "23/09/26 20:55:45 WARN MemoryStore: Not enough space to cache rdd_279_22 in memory! (computed 2.3 MiB so far)\n",
      "23/09/26 20:55:45 WARN BlockManager: Persisting block rdd_279_22 to disk instead.\n",
      "23/09/26 20:55:45 WARN MemoryStore: Not enough space to cache rdd_279_18 in memory! (computed 28.9 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_25 in memory! (computed 1025.1 KiB so far)\n",
      "23/09/26 20:55:46 WARN BlockManager: Persisting block rdd_279_25 to disk instead.\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_24 in memory! (computed 11.6 MiB so far)\n",
      "23/09/26 20:55:46 WARN BlockManager: Persisting block rdd_279_24 to disk instead.\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_0 in memory! (computed 3.5 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_2 in memory! (computed 2.3 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_7 in memory! (computed 5.2 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_5 in memory! (computed 3.4 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_3 in memory! (computed 5.1 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_1 in memory! (computed 5.2 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_4 in memory! (computed 5.4 MiB so far)\n",
      "23/09/26 20:55:46 WARN MemoryStore: Not enough space to cache rdd_279_6 in memory! (computed 5.2 MiB so far)\n",
      "23/09/26 20:55:48 WARN MemoryStore: Not enough space to cache rdd_279_9 in memory! (computed 12.6 MiB so far)\n",
      "23/09/26 20:55:48 WARN MemoryStore: Not enough space to cache rdd_279_15 in memory! (computed 5.2 MiB so far)\n",
      "23/09/26 20:55:48 WARN MemoryStore: Not enough space to cache rdd_279_11 in memory! (computed 19.0 MiB so far)\n",
      "23/09/26 20:55:48 WARN MemoryStore: Not enough space to cache rdd_279_13 in memory! (computed 22.0 MiB so far)\n",
      "23/09/26 20:55:53 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n",
      "23/09/26 20:56:55 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------------+-----+-------+-----+--------------------+-------------------+--------------------+\n",
      "|JobID|WindowID|             City|State|Country| Zip5|           StartDate|            EndDate|      tfidf_features|\n",
      "+-----+--------+-----------------+-----+-------+-----+--------------------+-------------------+--------------------+\n",
      "|    1|       1|       Washington|   DC|     US|20531|2012-03-07 13:17:...|2012-04-06 23:59:59|(262144,[0,5,7,10...|\n",
      "|    4|       1|        Charlotte|   NC|     US|28217|2012-03-21 02:03:...|2012-04-20 23:59:59|(262144,[1,2,5,8,...|\n",
      "|    7|       1|      Winter Park|   FL|     US|32792|2012-03-02 16:36:...|2012-04-01 23:59:59|(262144,[0,2,4,10...|\n",
      "|    8|       1|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|(262144,[1,18,22,...|\n",
      "|    9|       1|          Orlando|   FL|     US| null|2012-03-03 09:01:...|2012-04-02 23:59:59|(262144,[0,7,18,2...|\n",
      "|   10|       1|     Ormond Beach|   FL|     US|32174|2012-03-05 14:21:...|2012-04-04 23:59:59|(262144,[0,2,4,11...|\n",
      "|   11|       1|          Orlando|   FL|     US|32801|2012-03-06 09:21:...|2012-04-05 23:59:59|(262144,[0,22,26,...|\n",
      "|   12|       1|          Orlando|   FL|     US|32808|2012-03-06 11:21:...|2012-04-05 23:59:59|(262144,[0,22,26,...|\n",
      "|   13|       1|          Orlando|   FL|     US|32801|2012-03-06 16:06:...|2012-04-05 23:59:59|(262144,[0,19,22,...|\n",
      "|   14|       1|      Winter Park|   FL|     US|32789|2012-03-07 10:21:...|2012-04-06 23:59:59|(262144,[0,10,14,...|\n",
      "|   15|       1|      Los Angeles|   CA|     US|90011|2012-03-09 01:12:...|2012-04-08 23:59:59|(262144,[1,10,20,...|\n",
      "|   16|       1|         Longwood|   FL|     US|32779|2012-03-08 05:09:...|2012-04-07 23:59:59|(262144,[0,3,18,2...|\n",
      "|   17|       1|Altamonte Springs|   FL|     US|32714|2012-03-08 11:07:...|2012-04-07 23:59:59|(262144,[0,2,22,2...|\n",
      "|   18|       1|          Orlando|   FL|     US|32819|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,19,22,...|\n",
      "|   19|       1|    Daytona Beach|   FL|     US|32114|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,2,10,1...|\n",
      "|   20|       1|           Oviedo|   FL|     US|32765|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,2,5,7,...|\n",
      "|   21|       1|          Orlando|   FL|     US|32804|2012-03-09 16:21:...|2012-04-08 23:59:59|(262144,[0,22,26,...|\n",
      "|   22|       1|          Orlando|   FL|     US|32819|2012-03-09 16:51:...|2012-04-08 23:59:59|(262144,[0,1,2,3,...|\n",
      "|   23|       1|Altamonte Springs|   FL|     US|32701|2012-03-09 17:06:...|2012-04-08 23:59:59|(262144,[0,22,26,...|\n",
      "|   24|       1|       Windermere|   FL|     US|34786|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,3,22,2...|\n",
      "+-----+--------+-----------------+-----+-------+-----+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/26 20:56:55 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "# Concatenate the text from different columns into a single column\n",
    "jobs_df = jobs_df.withColumn(\"combined_text\", concat(col(\"Description\"), lit(\" \"), col(\"Requirements\")))\n",
    "\n",
    "# Tokenize the combined text\n",
    "tokenizer = Tokenizer(inputCol=\"combined_text\", outputCol=\"tokens\")\n",
    "jobs_df = tokenizer.transform(jobs_df)\n",
    "\n",
    "# Remove stopwords\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "jobs_df = stopwords_remover.transform(jobs_df)\n",
    "\n",
    "# Compute Term Frequencies\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"tf_features\")\n",
    "count_vectorizer_model = count_vectorizer.fit(jobs_df)\n",
    "jobs_df = count_vectorizer_model.transform(jobs_df)\n",
    "\n",
    "# Compute Inverse Document Frequencies\n",
    "idf = IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\")\n",
    "idf_model = idf.fit(jobs_df)\n",
    "jobs_df = idf_model.transform(jobs_df)\n",
    "\n",
    "# Drop intermediate columns\n",
    "jobs_df = jobs_df.drop(\"combined_text\", \"tokens\", \"filtered_tokens\", \"tf_features\")\n",
    "\n",
    "# Drop the source columns\n",
    "jobs_df = jobs_df.drop(\"Title\", \"Description\", \"Requirements\")\n",
    "\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "jobs_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ee989e6-ced7-4dba-85e5-e89f0472e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+--------------------+-------------------+--------------------+------------+-------------+---------------+\n",
      "|JobID|WindowID| Zip5|           StartDate|            EndDate|      tfidf_features|City_encoded|State_encoded|Country_encoded|\n",
      "+-----+--------+-----+--------------------+-------------------+--------------------+------------+-------------+---------------+\n",
      "|    1|       1|20531|2012-03-07 13:17:...|2012-04-06 23:59:59|(262144,[0,5,7,10...|        12.0|         32.0|            0.0|\n",
      "|    4|       1|28217|2012-03-21 02:03:...|2012-04-20 23:59:59|(262144,[1,2,5,8,...|         6.0|          8.0|            0.0|\n",
      "|    7|       1|32792|2012-03-02 16:36:...|2012-04-01 23:59:59|(262144,[0,2,4,10...|       480.0|          2.0|            0.0|\n",
      "|    8|       1| null|2012-03-03 09:01:...|2012-04-02 23:59:59|(262144,[1,18,22,...|        17.0|          2.0|            0.0|\n",
      "|    9|       1| null|2012-03-03 09:01:...|2012-04-02 23:59:59|(262144,[0,7,18,2...|        17.0|          2.0|            0.0|\n",
      "|   10|       1|32174|2012-03-05 14:21:...|2012-04-04 23:59:59|(262144,[0,2,4,11...|      1401.0|          2.0|            0.0|\n",
      "|   11|       1|32801|2012-03-06 09:21:...|2012-04-05 23:59:59|(262144,[0,22,26,...|        17.0|          2.0|            0.0|\n",
      "|   12|       1|32808|2012-03-06 11:21:...|2012-04-05 23:59:59|(262144,[0,22,26,...|        17.0|          2.0|            0.0|\n",
      "|   13|       1|32801|2012-03-06 16:06:...|2012-04-05 23:59:59|(262144,[0,19,22,...|        17.0|          2.0|            0.0|\n",
      "|   14|       1|32789|2012-03-07 10:21:...|2012-04-06 23:59:59|(262144,[0,10,14,...|       480.0|          2.0|            0.0|\n",
      "|   15|       1|90011|2012-03-09 01:12:...|2012-04-08 23:59:59|(262144,[1,10,20,...|         9.0|          0.0|            0.0|\n",
      "|   16|       1|32779|2012-03-08 05:09:...|2012-04-07 23:59:59|(262144,[0,3,18,2...|       893.0|          2.0|            0.0|\n",
      "|   17|       1|32714|2012-03-08 11:07:...|2012-04-07 23:59:59|(262144,[0,2,22,2...|       448.0|          2.0|            0.0|\n",
      "|   18|       1|32819|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,19,22,...|        17.0|          2.0|            0.0|\n",
      "|   19|       1|32114|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,2,10,1...|       253.0|          2.0|            0.0|\n",
      "|   20|       1|32765|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,2,5,7,...|      1452.0|          2.0|            0.0|\n",
      "|   21|       1|32804|2012-03-09 16:21:...|2012-04-08 23:59:59|(262144,[0,22,26,...|        17.0|          2.0|            0.0|\n",
      "|   22|       1|32819|2012-03-09 16:51:...|2012-04-08 23:59:59|(262144,[0,1,2,3,...|        17.0|          2.0|            0.0|\n",
      "|   23|       1|32701|2012-03-09 17:06:...|2012-04-08 23:59:59|(262144,[0,22,26,...|       448.0|          2.0|            0.0|\n",
      "|   24|       1|34786|2012-03-10 01:13:...|2012-04-09 23:59:59|(262144,[0,3,22,2...|      8566.0|          2.0|            0.0|\n",
      "+-----+--------+-----+--------------------+-------------------+--------------------+------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/26 20:57:06 WARN DAGScheduler: Broadcasting large task binary with size 9.3 MiB\n"
     ]
    }
   ],
   "source": [
    "# Numerically encode these columns ['City', 'State', 'Country', 'CurrentlyEmployed', 'ManagedOthers']\n",
    "categorical_columns = ['City', 'State', 'Country']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    encoded_column = col + \"_encoded\"\n",
    "    string_indexer = StringIndexer(inputCol=col, outputCol=encoded_column)\n",
    "    jobs_df = string_indexer.fit(jobs_df).transform(jobs_df)\n",
    "\n",
    "columns_to_drop = ['City', 'State', 'Country']\n",
    "jobs_df = jobs_df.drop(*columns_to_drop)\n",
    "# Show the resulting DataFrame with the encoded column\n",
    "jobs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a518b3c-cc2a-40a1-a65a-1b72acc22508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
