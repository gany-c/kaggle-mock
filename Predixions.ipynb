{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064a513c-2e0c-4754-ae7f-5a74d49140e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Python Notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Python Notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171c2b83-6c92-47a9-93dd-cb72ed24e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m apache-spark 3.5.0 is already installed and up-to-date.\n",
      "To reinstall 3.5.0, run:\n",
      "  brew reinstall apache-spark\n"
     ]
    }
   ],
   "source": [
    "!brew install apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13003dd-ac5f-4337-aa16-634a33552ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed installing apache-spark\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed installing apache-spark\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd91fb72-3dc8-47da-8a11-1cbb99d37387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m openjdk@11 11.0.20.1 is already installed and up-to-date.\n",
      "To reinstall 11.0.20.1, run:\n",
      "  brew reinstall openjdk@11\n"
     ]
    }
   ],
   "source": [
    "!brew install openjdk@11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6e1f8-eb81-4278-aaa7-6a0ee605a01b",
   "metadata": {},
   "source": [
    "### The above Java installation doesn't work immediately. If you do a \"re-install\" it tells which commands need to be run to fix the path variable etc.\n",
    "\n",
    "   ### (echo; echo 'eval \"$(/opt/homebrew/bin/brew shellenv)\"') >> /Users/ganapathychidambaram/.zprofile\n",
    "\n",
    "   \n",
    "   ### eval \"$(/opt/homebrew/bin/brew shellenv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0425c723-0643-4240-99fd-2b69e3de667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a38c1c6-21f0-4160-a73b-b86c276fa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export JAVA_HOME=/usr\n",
    "!export PATH=$JAVA_HOME/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18229829-990e-4c42-98ca-334af4589231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk 11.0.20.1 2023-08-24\n",
      "OpenJDK Runtime Environment Homebrew (build 11.0.20.1+0)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 11.0.20.1+0, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd784401-e13d-4d25-b350-48345abe1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export SPARK_HOME=/opt/homebrew/Cellar/apache-spark/3.3.0/libexec\n",
    "!export PATH=/opt/homebrew/Cellar/apache-spark/3.3.0/bin:$PATH\n",
    "\n",
    "# looks the case of the JAVA_HOME variable made all the difference    \n",
    "\n",
    "!export PYSPARK_SUBMIT_ARGS=\"--master local[3] pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dde423b-4dad-4a69-9c95-416684911096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m226.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=0264f33038adefac06860f978e16564f27e873197b913c1c095d93a28bde7f77\n",
      "  Stored in directory: /Users/ganapathychidambaram/Library/Caches/pip/wheels/e9/b4/d8/38accc42606f6675165423e9f0236f8e825f6b6b6048d6743e\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.1\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark\n",
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c088f31a-be45-4491-91be-032931a9221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36414768-d885-4265-b091-44dd1e7fb525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/25 22:47:50 WARN Utils: Your hostname, Ganapathys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.7 instead (on interface en0)\n",
      "23/09/25 22:47:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/25 22:47:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02160d43-3a56-451d-8430-dae67fd3051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"/Users/ganapathychidambaram/Desktop/predixions/apps.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda1c07e-60ba-4b73-91fb-42eac9e6dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+--------------------+-------+\n",
      "|UserID|WindowID|Split|     ApplicationDate|  JobID|\n",
      "+------+--------+-----+--------------------+-------+\n",
      "|    47|       1|Train|2012-04-04 15:56:...| 169528|\n",
      "|    47|       1|Train|2012-04-06 01:03:...| 284009|\n",
      "|    47|       1|Train|2012-04-05 02:40:...|   2121|\n",
      "|    47|       1|Train|2012-04-05 02:37:...| 848187|\n",
      "|    47|       1|Train|2012-04-05 22:44:...| 733748|\n",
      "|    47|       1|Train|2012-04-05 02:34:...| 576958|\n",
      "|    47|       1|Train|2012-04-05 22:55:...| 262470|\n",
      "|    47|       1|Train|2012-04-05 02:38:...| 602298|\n",
      "|    72|       1|Train|2012-04-02 22:36:...| 834662|\n",
      "|    72|       1|Train|2012-04-07 15:19:...|1020903|\n",
      "|    72|       1|Train|2012-04-07 17:38:...| 180313|\n",
      "|    72|       1|Train|2012-04-30 20:05:...| 480634|\n",
      "|    72|       1|Train|2012-04-20 02:51:...| 564184|\n",
      "|    80|       1|Train|2012-04-04 10:53:...| 908909|\n",
      "|   123|       1|Train|2012-04-02 20:57:...|1080147|\n",
      "|   123|       1|Train|2012-04-02 21:03:...|1080148|\n",
      "|   131|       1|Train|2012-04-02 14:06:...| 688863|\n",
      "|   131|       1|Train|2012-04-05 15:08:...|1092900|\n",
      "|   131|       1|Train|2012-04-05 17:09:...|  50183|\n",
      "|   162|       1|Train|2012-04-06 14:25:...|  69667|\n",
      "+------+--------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "applications_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebe697-a1de-4dc3-b9b9-cb756d09b870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
